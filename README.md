# ðŸŽ¬ Subtitle Learning Lab

A practical subtitle engine for local media: **list, extract, transcribe, translate, and merge** subtitle tracks.

> Scope note: this repo is now **engine-only**. Learning markdown/vocabulary generation is being split into a separate skill.

## Core Workflow

```mermaid
flowchart TD
    A[Video/Audio File] --> B{Subtitles present?}
    B -->|Yes, multiple| C[Merge selected tracks]
    B -->|Yes, one| D[Translate if needed]
    B -->|No| E[Transcribe with Whisper]
    E --> D
    D --> F[Optional merge]
    C --> G[Output SRT]
    F --> G
```

## Features

- Inspect subtitle streams in MKV/MP4/etc.
- Extract subtitle tracks by index or language
- Convert subtitle tracks to SRT
- Transcribe audio/video to SRT via Whisper
- Translate subtitle files with OpenAI-compatible APIs
- Merge tracks using overlap-based alignment

## Prerequisites

- Python 3.9+
- `ffmpeg` + `ffprobe`
- Optional for translate: `openai`, `python-dotenv`
- Optional for transcribe: `whisper` CLI

## Quick Start

```bash
# 1) List subtitle tracks
python scripts/learning_lab.py list movie.mkv

# 2) Extract English subtitle track to SRT
python scripts/learning_lab.py extract movie.mkv --language eng --to-srt

# 3) Translate SRT to Chinese
python scripts/learning_lab.py translate movie.eng.srt --target-language "Chinese"

# 4) Merge English + Chinese tracks from container
python scripts/learning_lab.py merge movie.mkv --languages eng chi

# 5) If no subtitles exist, transcribe first
python scripts/learning_lab.py transcribe movie.mkv --model turbo
```

## CLI Commands

### `list`
```bash
python scripts/learning_lab.py list <video>
```

### `extract`
```bash
python scripts/learning_lab.py extract <video> [--index N | --language CODE] [--to-srt] [--output PATH]
```

### `merge`
```bash
python scripts/learning_lab.py merge <video> [--indices N N | --languages CODE CODE] [--output PATH]
```

### `translate`
```bash
python scripts/learning_lab.py translate <srt-or-video> --target-language "Chinese" [--api-key ...] [--base-url ...] [--model ...] [--output ...]
```

### `transcribe`
```bash
python scripts/learning_lab.py transcribe <video-or-audio> [--model turbo] [--language en] [--output PATH]
```

## Output Convention

- `movie.eng.srt`
- `movie.zho.srt`
- `movie.eng-chi.merged.srt`

## Example Output Files

When testing the skill on a sample video in the `tests/` directory, the following files are naturally generated:

- `The best way to become good at something might surprise you - David Epstein.srt` (generated by transcription)
- `The best way to become good at something might surprise you - David Epstein.chinese.srt` (generated by translation)

## Project Structure

```text
subtitle-learning-lab/
â”œâ”€â”€ SKILL.md
â”œâ”€â”€ README.md
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ learning_lab.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_merge.py
â”‚   â””â”€â”€ test_translation.py
â””â”€â”€ references/
    â””â”€â”€ subtitle-notes.md
```

## Development

Run tests:
```bash
python3 -m pytest tests -v
```

## Roadmap

- [x] list / extract / merge
- [x] OpenAI-compatible translation
- [x] Whisper transcription
- [ ] API-backed transcription provider interface (optional backend)
- [ ] Chunked long-video pipeline for reliability

## License

Internal skill / private workflow project.
